{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers with Fastai.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJK1BC9grFxL2PtWclSifm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitramir55/kaggle-sentiment-analysis-project/blob/main/Transformers_with_Fastai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlHFNRPrX1Ml",
        "outputId": "b715d92a-dffa-4afd-d88f-6d05aab3ef4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-o7bu5oej\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-o7bu5oej\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied (use --upgrade to upgrade): transformers==3.4.0 from git+https://github.com/huggingface/transformers in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.1.91)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (0.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.4.0) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.4.0) (50.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.4.0) (2.4.7)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.4.0-cp36-none-any.whl size=1257324 sha256=a3e0bcb1c588761673eb7d95199321b1c28f8c44af66c4b80f08face9002cac2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mhyb1hz9/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "Successfully built transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_-BkA24zMAO"
      },
      "source": [
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsj1fb7kWOrY",
        "outputId": "84d78f51-e9cf-4f2b-e900-4be4f914f0de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "source": [
        "import fastai\n",
        "import transformers\n",
        "print('fastai version :', fastai.__version__)\n",
        "print('transformers version :', transformers.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai version : 1.0.61\n",
            "transformers version : 3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzIR--MtfK8"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import random \n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBtYiiEOss39",
        "outputId": "272cff4e-0934-4755-ee58-cd4dd7658626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "\n",
        "!git clone https://github.com/mitramir55/kaggle-sentiment-analysis-project.git\n",
        "train = pd.read_csv('kaggle-sentiment-analysis-project/train.tsv', sep = '\\t')\n",
        "test = pd.read_csv('kaggle-sentiment-analysis-project/test.tsv', sep = '\\t')\n",
        "#sample_sub = pd.read_csv('kaggle-sentiment-analysis-project/sample_submission.csv')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kaggle-sentiment-analysis-project' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcfAGL_KkWWi"
      },
      "source": [
        "import string\n",
        "def clean(tweet, http = True, punc = True, lem = True, stop_w = True):\n",
        "    \n",
        "    if http is True:\n",
        "        tweet = re.sub(\"https?:\\/\\/t.co\\/[A-Za-z0-9]*\", '', tweet)\n",
        "\n",
        "    \n",
        "    if stop_w == 'nltk':\n",
        "        tweet = [word for word in word_tokenize(tweet) if not word.lower() in nltk_st]\n",
        "        tweet = ' '.join(tweet)\n",
        "\n",
        "    elif stop_w == 'spacy':\n",
        "        tweet = [word for word in word_tokenize(tweet) if not word.lower() in spacy_st]\n",
        "        tweet = ' '.join(tweet)\n",
        "\n",
        "    # lemmitizing\n",
        "    if lem == True:\n",
        "        lemmatized = [word.lemma_ for word in sp(tweet)]\n",
        "        tweet = ' '.join(lemmatized)\n",
        "\n",
        "    # punctuation removal\n",
        "    if punc is True:\n",
        "        tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
        "        \n",
        "    # removing extra space\n",
        "    tweet = re.sub(\"\\s+\", ' ', tweet)\n",
        "    \n",
        "    return tweet\n",
        "train['Phrase'] = train.Phrase.apply(lambda x: clean(x, lem = False, stop_w = False, http = False, punc = True))\n",
        "test['Phrase'] = test.Phrase.apply(lambda x: clean(x, lem = False, stop_w = False, http = False, punc = True))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFoP6Rfdvkd9"
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKMlhKALv_kl"
      },
      "source": [
        "# Parameters\n",
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 16\n",
        "\n",
        "model_type = 'roberta'\n",
        "pretrained_model_name = 'roberta-base'\n",
        "\n",
        "# model_type = 'bert'\n",
        "# pretrained_model_name='bert-base-uncased'\n",
        "\n",
        "# model_type = 'distilbert'\n",
        "# pretrained_model_name = 'distilbert-base-uncased'\n",
        "\n",
        "#model_type = 'xlm'\n",
        "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
        "\n",
        "# model_type = 'xlnet'\n",
        "# pretrained_model_name = 'xlnet-base-cased'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMfk5id_xkDe"
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GJKbqujxnTQ"
      },
      "source": [
        "#transformers.RobertaForSequenceClassification.pretrained_model_archive_map.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXvKn-qyxzvM"
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"it coms from transformers and we want to\n",
        "    make it compatible with the fast.ai\"\"\"\n",
        "\n",
        "    def __init__(self, pretrained_tokenizer :PreTrainedTokenizer,\n",
        "                 model_type = 'bert', **kwargs):\n",
        "        \n",
        "        # why _pretrained ?\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        \"\"\"add this max_len to your model\"\"\"\n",
        "\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __cal__(self, *args, **kwargs):\n",
        "        return self\n",
        "    \n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type == 'roberta':\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space = True)[:self.max_seq_len - 2]\n",
        "            tokens = [CLS] + tokens + [SEP]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:max_seq_len -2]\n",
        "\n",
        "            if self.model_type == 'xlnet':\n",
        "                tokens = tokens + [SEP] + [CLS]\n",
        "            else:\n",
        "                tokens = [SEP] + tokens + [CLS]\n",
        "        return tokens"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4jWpDkb5jZP"
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "            tokens = [CLS] + tokens + [SEP]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "            if self.model_type in ['xlnet']:\n",
        "                tokens = tokens + [SEP] +  [CLS]\n",
        "            else:\n",
        "                tokens = [CLS] + tokens + [SEP]\n",
        "        return tokens"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oROxUBhaQb8l",
        "outputId": "3b375620-c1c6-4040-8577-fcc3b9ce34e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "# defining transformer tokenizer\n",
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer,\n",
        "                                                       model_type = model_type)\n",
        "# giving this transformer tokenizer to fastai tokenizer\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1374: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYYEPWHvRWks"
      },
      "source": [
        "# we transform tokens to ids : numericalize\n",
        "# convert ids to tokens : textify"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r66Xg0lx1Zw-"
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def numericalize(self, t: Collection[str]) -> List[int]:\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "\n",
        "    def textify(self, nums: Collection[int], sep = ' ') -> List[str]:\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
        "    \n",
        "    # itos: a list of all the words in vocabulary\n",
        "    # exporting the model\n",
        "    # whatever comes out will be a dict, int, list, something picklable\n",
        "    def __getstate__(self):\n",
        "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "    def __setstate__(self, state:dict):\n",
        "        self.itos = state['itos']\n",
        "        self.tokenizer = state['tokenizer']\n",
        "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h3dC7X81ZfV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iW7eC_Lc-1H"
      },
      "source": [
        "transformer_vocab = TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab = transformer_vocab)\n",
        "tokenize_processor = TokenizeProcessor(tokenizer = fastai_tokenizer,\n",
        "                                       include_bos = False,\n",
        "                                       include_eos = False)\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAL57_i7c_UJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFKEtZeii_FG"
      },
      "source": [
        "In fastai the data-containing object that we need to feed to a neural network is called a DataBunch. This is called a ‘bunch’ because it bunches together several PyTorch classes into one. In PyTorch there are two primary data objects: **the DataSet** (which contains all of the data items together with their associated label(s)), and the **DataLoader** (which gives chunks of the items in the DataSet to the model in ‘batches’ ). For a typical supervised learning problem we will want a ‘training set’ and a ‘validation set’, with a separateDataSet and DataLoader for each. (as well as an optional ‘test set’, which we will ignore here for simplicity) All of these are bundled up into the fastai DataBunch!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAeC4LLFzfQQ"
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeAWe6Hnc_XL",
        "outputId": "044ef1a8-f587-4e60-dcde-cea6e0eb3a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "databunch = (TextList.from_df(train, cols='Phrase', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'Sentiment')\n",
        "             .add_test(test)# databunch: batch size, padding, idx of pad\n",
        "             .databunch(bs=bs , pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAvbzrG6c_Ph"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36q_5D2_i9iK",
        "outputId": "0d30bcee-19b9-4ae0-a813-3996db0c8101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "print('CLS token in RoBERTa: ', transformer_tokenizer.cls_token)\n",
        "print('SEP token in RoBERTa: ', transformer_tokenizer.sep_token)\n",
        "print('pad in RoBERTa: ', transformer_tokenizer.pad_token)\n",
        "print('CLS id in RoBERTa: ', transformer_tokenizer.cls_token_id)\n",
        "print('SEP id in RoBERTa: ', transformer_tokenizer.sep_token_id)\n",
        "print('pad id in RoBERTa: ', transformer_tokenizer.pad_token_id)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CLS token in RoBERTa:  <s>\n",
            "SEP token in RoBERTa:  </s>\n",
            "pad in RoBERTa:  <pad>\n",
            "CLS id in RoBERTa:  0\n",
            "SEP id in RoBERTa:  2\n",
            "pad id in RoBERTa:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdjOIuPeZXDy",
        "outputId": "9061c261-a1bf-4478-de74-0d91f346f2f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "sent = \"Hello babe, It's me\"\n",
        "tokens = transformer_tokenizer.tokenize(sent)\n",
        "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
        "print('tokens are: \\n', tokens)\n",
        "print('ids are: \\n', ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokens are: \n",
            " ['Hello', 'Ġbabe', ',', 'ĠIt', \"'s\", 'Ġme']\n",
            "ids are: \n",
            " [31414, 37502, 6, 85, 18, 162]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D85AYdq_1Zcg",
        "outputId": "de381604-8d29-43e0-db29-e054a682f9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "transformer_base_tokenizer.tokenizer(\"me I'm so good, meee\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'Ġme', 'ĠI', \"'m\", 'Ġso', 'Ġgood', ',', 'Ġme', 'ee', '</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDLyXetYwOtY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jUviyeWwOyj",
        "outputId": "5ef3bdab-dbb5-408e-80e9-168a916f6605",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "print('CLS token in BERT: ', transformer_tokenizer.cls_token)\n",
        "print('SEP token in BERTa: ', transformer_tokenizer.sep_token)\n",
        "print('pad in BERTa: ', transformer_tokenizer.pad_token)\n",
        "print('CLS id in BERTa: ', transformer_tokenizer.cls_token_id)\n",
        "print('SEP id in BERTa: ', transformer_tokenizer.sep_token_id)\n",
        "print('pad id in BERTa: ', transformer_tokenizer.pad_token_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CLS token in BERT:  [CLS]\n",
            "SEP token in BERTa:  [SEP]\n",
            "pad in BERTa:  [PAD]\n",
            "CLS id in BERTa:  101\n",
            "SEP id in BERTa:  102\n",
            "pad id in BERTa:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5OG4FxEwOvN"
      },
      "source": [
        "sent = \"Hello babe, It's me\"\n",
        "tokens = transformer_tokenizer.tokenize(sent)\n",
        "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
        "print('tokens are: \\n', tokens)\n",
        "print('ids are: \\n', ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1-0yV96wOl1",
        "outputId": "98c8fbe5-1976-43ed-d999-d3d435ece54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "databunch.show_batch()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fastai/text/data.py:339: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  idx_min = (t != self.pad_idx).nonzero().min()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; ĠL RB ĠCity ĠRR B Ġreminds Ġus Ġhow Ġrealistically Ġnuanced Ġa ĠRobert ĠDe ĠN iro Ġperformance Ġcan Ġbe Ġwhen Ġhe Ġis Ġnot Ġmore Ġluc r atively Ġengaged Ġin Ġthe Ġshameless Ġself car ic ature Ġof ĠAnaly ze ĠThis ĠL RB Ġ1999 ĠRR B Ġand ĠAnaly ze ĠThat Ġpromised ĠL RB Ġor Ġthreatened ĠRR B Ġfor Ġlater Ġthis Ġyear Ġ &lt;/s&gt;</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; ĠThe Ġreal Ġtriumph s Ġin ĠIg by Ġcome Ġfrom ĠPhilippe Ġwho Ġmakes ĠOliver Ġfar Ġmore Ġinteresting Ġthan Ġthe Ġcharacter Ġs Ġlines Ġwould Ġsuggest Ġand ĠSar andon Ġwho Ġcould Ġn t Ġbe Ġbetter Ġas Ġa Ġcruel Ġbut Ġweird ly Ġlik able ĠWAS P Ġmat ron Ġ &lt;/s&gt;</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; ĠParker Ġshould Ġbe Ġcomm ended Ġfor Ġtaking Ġa Ġfresh Ġapproach Ġto Ġfamiliar Ġmaterial Ġbut Ġhis Ġdetermination Ġto Ġremain Ġtrue Ġto Ġthe Ġoriginal Ġtext Ġleads Ġhim Ġto Ġadopt Ġa Ġsomewhat Ġman nered Ġtone Ġthat Ġultimately Ġdull s Ġthe Ġhuman Ġtragedy Ġat Ġthe Ġstory Ġs Ġcore &lt;/s&gt;</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; ĠA Ġdifferent Ġand Ġemotionally Ġreserved Ġtype Ġof Ġsurvival Ġstory Ġa Ġfilm Ġless Ġabout Ġref ract ing Ġall Ġof ĠWorld ĠWar ĠII Ġthrough Ġthe Ġspecific Ġconditions Ġof Ġone Ġman Ġand Ġmore Ġabout Ġthat Ġman Ġlost Ġin Ġits Ġmidst Ġ &lt;/s&gt;</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; ĠIt Ġs Ġa Ġlong Ġway Ġfrom ĠOrwell Ġs Ġdark Ġintelligent Ġwarning Ġcry ĠL RB Ġ1984 ĠRR B Ġto Ġthe Ġempty Ġstud Ġknock about Ġof ĠEqu ilibrium Ġand Ġwhat Ġonce Ġwas Ġconviction Ġis Ġnow Ġaffect ation Ġ &lt;/s&gt;</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9LvhMdbfQ5C"
      },
      "source": [
        "databunch.one_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRYvycgNembL"
      },
      "source": [
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel, self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "\n",
        "    def forward(self, input_ids, attention_mask = None):\n",
        "        attention_mask = (input_ids!=pad_idx).type(input_ids.type())\n",
        "        logits = self.transformer(input_ids,\n",
        "                                  attention_mask = attention_mask)[0]\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezLpQW-8fehC",
        "outputId": "054fcd31-e1a4-4c08-d1f6-3c1fb96ae924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        }
      },
      "source": [
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = 5\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2LviAE0fe6w",
        "outputId": "d4d78094-d6ab-4e6a-d7f1-b424ce3aa964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model= transformer_model)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kp12PgNlKkR"
      },
      "source": [
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "from functools import partial\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLuhl4RAfekC"
      },
      "source": [
        "CustomAdamW = partial(AdamW, correct_bias = False)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "learner = Learner(databunch,\n",
        "                  custom_transformer_model,\n",
        "                  opt_func = CustomAdamW,\n",
        "                  metrics = [accuracy, error_rate])\n",
        "\n",
        "\n",
        "\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwd4Dzmafebw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3QciUbMvlKB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIV979JuvlGX"
      },
      "source": [
        "learner.save('untrain')\n",
        "seed_all(seed)\n",
        "learner.load('untrain');\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-QjRKimxgKI"
      },
      "source": [
        "print(learner.model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWeTTAsrxPQS",
        "outputId": "bfe63207-3635-4dc4-baaa-988d5fce18b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CustomTransformerModel\n",
              "======================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "======================================================================\n",
              "Embedding            [61, 768]            38,603,520 True      \n",
              "______________________________________________________________________\n",
              "Embedding            [61, 768]            394,752    True      \n",
              "______________________________________________________________________\n",
              "Embedding            [61, 768]            768        True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 61, 61]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [61, 3072]           2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [61, 768]            2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [61, 768]            1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [61, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [768]                590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [5]                  3,845      True      \n",
              "______________________________________________________________________\n",
              "\n",
              "Total params: 124,649,477\n",
              "Total trainable params: 124,649,477\n",
              "Total non-trainable params: 0\n",
              "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
              "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
              "Loss function : FlattenedLoss\n",
              "======================================================================\n",
              "Callbacks functions applied \n",
              "    ShowGraph"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg6BtVu2vlE4"
      },
      "source": [
        ""
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiWz73sfzgYw"
      },
      "source": [
        "learner.freeze_to(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQsW8e0RzlZ4"
      },
      "source": [
        ""
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un-ePrUSzo28"
      },
      "source": [
        "# For DistilBERT\n",
        "# list_layers = [learner.model.transformer.distilbert.embeddings,\n",
        "#                learner.model.transformer.distilbert.transformer.layer[0],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[1],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[2],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[3],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[4],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[5],\n",
        "#                learner.model.transformer.pre_classifier]\n",
        "\n",
        "# For xlnet-base-cased\n",
        "# list_layers = [learner.model.transformer.transformer.word_embedding,\n",
        "#               learner.model.transformer.transformer.layer[0],\n",
        "#               learner.model.transformer.transformer.layer[1],\n",
        "#               learner.model.transformer.transformer.layer[2],\n",
        "#               learner.model.transformer.transformer.layer[3],\n",
        "#               learner.model.transformer.transformer.layer[4],\n",
        "#               learner.model.transformer.transformer.layer[5],\n",
        "#               learner.model.transformer.transformer.layer[6],\n",
        "#               learner.model.transformer.transformer.layer[7],\n",
        "#               learner.model.transformer.transformer.layer[8],\n",
        "#               learner.model.transformer.transformer.layer[9],\n",
        "#               learner.model.transformer.transformer.layer[10],\n",
        "#               learner.model.transformer.transformer.layer[11],\n",
        "#               learner.model.transformer.sequence_summary]\n",
        "\n",
        "# For roberta-base\n",
        "list_layers = [learner.model.transformer.roberta.embeddings,\n",
        "              learner.model.transformer.roberta.encoder.layer[0],\n",
        "              learner.model.transformer.roberta.encoder.layer[1],\n",
        "              learner.model.transformer.roberta.encoder.layer[2],\n",
        "              learner.model.transformer.roberta.encoder.layer[3],\n",
        "              learner.model.transformer.roberta.encoder.layer[4],\n",
        "              learner.model.transformer.roberta.encoder.layer[5],\n",
        "              learner.model.transformer.roberta.encoder.layer[6],\n",
        "              learner.model.transformer.roberta.encoder.layer[7],\n",
        "              learner.model.transformer.roberta.encoder.layer[8],\n",
        "              learner.model.transformer.roberta.encoder.layer[9],\n",
        "              learner.model.transformer.roberta.encoder.layer[10],\n",
        "              learner.model.transformer.roberta.encoder.layer[11],\n",
        "              learner.model.transformer.roberta.pooler]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLBfdzv3xHCi",
        "outputId": "8c63a08f-a342-4027-b194-d2f6dcf83722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='69' class='' max='8778' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.79% [69/8778 04:01<8:28:05 3.7302]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C8VxUYBxTZ1",
        "outputId": "4e26a88c-0fe4-4bb9-c916-10fc9b2fb8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "learner.recorder.plot(skip_end=10,suggestion=True)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min numerical gradient: 3.63E-05\n",
            "Min loss divided by 10: 1.91E-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfCbUwsq72Lw",
        "outputId": "647248f8-7db5-453f-e947-81070f74bfb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "learner.fit_one_cycle(1, max_lr=2e-05,  moms =(0.8,0.7)) "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2009' class='' max='8778' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      22.89% [2009/8778 1:33:17<5:14:20 0.8498]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-b5ea92254664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-05\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmoms\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/callback.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue_wd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpg2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_wd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCp1BgY9AfJ7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}